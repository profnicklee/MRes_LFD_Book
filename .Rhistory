})
junk <- lapply(c(5,10,50,100), function(N){
ci.examp(mean.sim   = 171,
sd         = 5.5,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
xlim     = 171 + 2 * 5.5 * c(-1, 1)
)
})
junk <- lapply(c(5,10,50,100), function(N){
ci.examp(mean.sim   = 171,
sd         = 5.5,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
xlim(171 + 2 * 5.5 * c(-1, 1))
)
})
junk <- lapply(c(5,10,50,100), function(N){
ci.examp(mean.sim   = 171,
sd         = 5.5,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
)
})
data <- matrix( rnorm( n*reps, mean.sim, sd), ncol=n)
ci.examp <- function(mean.sim=100, sd=10, n=25, reps=50,
conf.level=0.95, method="z",
lower.conf=(1-conf.level)/2,
upper.conf=1-(1-conf.level)/2,
XLIM = 100 + 40*c(-1,1))
{
data <- matrix( rnorm( n*reps, mean.sim, sd), ncol=n)
rmeans <- rowMeans(data)
switch(method, Z=,z={
lower <- qnorm( lower.conf, rmeans, sd/sqrt(n))
upper <- qnorm( upper.conf, rmeans, sd/sqrt(n))
},
T=,t= {
cv.l <- qt(lower.conf, n-1)
cv.u <- qt(upper.conf, n-1)
rsds <- sqrt( apply(data,1,var) )/sqrt(n)
lower <- rmeans+cv.l*rsds
upper <- rmeans+cv.u*rsds
},
BOTH=, Both=, both={
lz <- qnorm( lower.conf, rmeans, sd/sqrt(n))
uz <- qnorm( upper.conf, rmeans, sd/sqrt(n))
cv.l <- qt(lower.conf, n-1)
cv.u <- qt(upper.conf, n-1)
rsds <- sqrt( apply(data,1,var) )/sqrt(n)
lt <- rmeans+cv.l*rsds
ut <- rmeans+cv.u*rsds
lower <- c(rbind(lt,lz,mean.sim))
upper <- c(rbind(ut,uz,mean.sim))
reps <- reps*3
rmeans <- rep(rmeans, each=3)
rmeans[c(F,F,T)] <- NA
},
stop("method must be z, t, or both") )
if( any( upper==Inf ) ) upper <- rep( 2*mean.sim-min(lower), reps )
if( any( lower==-Inf ) ) lower <- rep( 2*mean.sim-max(upper), reps )
xr <- range( upper, lower )
plot(lower,seq(1,reps), type="n",
xlim=XLIM,       ## Changed
xlab="Confidence Interval",
ylab="Index",)
## abline( v= qnorm(c(1-upper.conf,1-lower.conf), mean.sim, sd/sqrt(n)), col=10) ## Deleted
title(paste("Sample size is", n, "each"))     ## Changed
colr <- ifelse( lower > mean.sim, 5, ifelse( upper < mean.sim, 6, 1) )
abline(v=mean.sim)
for( i in seq(1,reps) ){
segments(lower[i], i, upper[i], i, col=colr[i])
}
points( rmeans, seq(along=rmeans), pch="|" )
invisible(NULL)
}
## Height distribution for 20 year old males in 2011
POPULATION.MEAN <- 171.66
POPULATION.SD <- 5.60
## Repeat at different sample size
junk <- lapply(c(5,10,50,100), function(N){
ci.examp(mean.sim   = POPULATION.MEAN,
sd         = POPULATION.SD,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
XLIM       = POPULATION.MEAN + 2 * POPULATION.SD * c(-1, 1)
)
})
## Example numbers from slide deck - imaginary WBS PhD Salaries
POPULATION.MEAN <- 165
POPULATION.SD <- 40
## Repeat at different sample size including 42 from example in class
junk <- lapply(c(5,10,42,100), function(N){
ci.examp(mean.sim   = POPULATION.MEAN,
sd         = POPULATION.SD,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
XLIM       = POPULATION.MEAN + 2 * POPULATION.SD * c(-1, 1)
)
})
## Example numbers from slide deck - imaginary WBS PhD Salaries
POPULATION.MEAN <- 165
POPULATION.SD <- 40
## Repeat at different sample size including 42 from example in class
junk <- lapply(c(5,10,42,100), function(N){
ci.examp(mean.sim   = POPULATION.MEAN,
sd         = POPULATION.SD,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
XLIM       = POPULATION.MEAN + 2 * POPULATION.SD * c(-1, 1)
)
})
ci.examp <- function(mean.sim=100, sd=10, n=25, reps=50,
conf.level=0.95, method="z",
lower.conf=(1-conf.level)/2,
upper.conf=1-(1-conf.level)/2,
XLIM = 100 + 40*c(-1,1))
{
data <- matrix( rnorm( n*reps, mean.sim, sd), ncol=n)
rmeans <- rowMeans(data)
switch(method, Z=,z={
lower <- qnorm( lower.conf, rmeans, sd/sqrt(n))
upper <- qnorm( upper.conf, rmeans, sd/sqrt(n))
},
T=,t= {
cv.l <- qt(lower.conf, n-1)
cv.u <- qt(upper.conf, n-1)
rsds <- sqrt( apply(data,1,var) )/sqrt(n)
lower <- rmeans+cv.l*rsds
upper <- rmeans+cv.u*rsds
},
BOTH=, Both=, both={
lz <- qnorm( lower.conf, rmeans, sd/sqrt(n))
uz <- qnorm( upper.conf, rmeans, sd/sqrt(n))
cv.l <- qt(lower.conf, n-1)
cv.u <- qt(upper.conf, n-1)
rsds <- sqrt( apply(data,1,var) )/sqrt(n)
lt <- rmeans+cv.l*rsds
ut <- rmeans+cv.u*rsds
lower <- c(rbind(lt,lz,mean.sim))
upper <- c(rbind(ut,uz,mean.sim))
reps <- reps*3
rmeans <- rep(rmeans, each=3)
rmeans[c(F,F,T)] <- NA
},
stop("method must be z, t, or both") )
if( any( upper==Inf ) ) upper <- rep( 2*mean.sim-min(lower), reps )
if( any( lower==-Inf ) ) lower <- rep( 2*mean.sim-max(upper), reps )
xr <- range( upper, lower )
plot(lower,seq(1,reps), type="n",
xlim=XLIM,       ## Changed
xlab="Confidence Interval",
ylab="Index",)
## abline( v= qnorm(c(1-upper.conf,1-lower.conf), mean.sim, sd/sqrt(n)), col=10) ## Deleted
title(paste("Sample size is", n, "each"))     ## Changed
colr <- ifelse( lower > mean.sim, 5, ifelse( upper < mean.sim, 6, 1) )
abline(v=mean.sim)
for( i in seq(1,reps) ){
segments(lower[i], i, upper[i], i, col=colr[i])
}
points( rmeans, seq(along=rmeans), pch="|" )
invisible(NULL)
}
## Example numbers from slide deck - imaginary WBS PhD Salaries sample was 170K, SD was 46617.4
POPULATION.MEAN <- 165
POPULATION.SD <- 40
## Repeat at different sample size including 42 from example in class
junk <- lapply(c(5,10,42,100), function(N){
ci.examp(mean.sim   = POPULATION.MEAN,
sd         = POPULATION.SD,
n          = N,
reps       = 100,
conf.level = 0.95,
method     = "z",
XLIM       = POPULATION.MEAN + 2 * POPULATION.SD * c(-1, 1)
)
})
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#note: some of these aren't used for the code that I run, but for other parts I have hashed out.
library(tidyverse)
library(combinat)
library(gtools)
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(dplyr)
library(gganimate)
library(gifski)
library(png)
library(installr)
library(skimr)
library(rstatix)
library(pwr)
Happy<-read_excel("Data/HappyGDP.xlsx", sheet = "2020")
summary(Happy)
head(Happy)
Assoc1 <- cor.test(Happy$Happiness, Happy$GDPpc,
method = "pearson")
Assoc1
Heart<-read_excel("Data/heart.data.xlsx")
summary(Heart)
head(Heart)
heart.disease.lm<-lm(heart.disease ~ biking + smoking, data = Heart)
summary(heart.disease.lm)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#note: some of these aren't used for the code that I run, but for other parts I have hashed out.
library(tidyverse)
library(combinat)
library(gtools)
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(dplyr)
library(gganimate)
library(gifski)
library(png)
library(installr)
library(skimr)
library(rstatix)
library(pwr)
ED<-read_excel("Data/SHEERAN_ANOVA.xlsx", sheet = "ANOVA")
describe(ED)
ED<-read_excel("Data/SHEERAN_ANOVA.xlsx", sheet = "ANOVA")
summary(ED)
head(ED)
ED<-read_excel("Data/SHEERAN_ANOVA.xlsx", sheet = "ANOVA")
ED$GROUP <- factor(ED$GROUP)
skim(ED)
summary(ED)
head(ED)
ED<-read_excel("Data/SHEERAN_ANOVA.xlsx", sheet = "ANOVA")
ED$GROUP <- factor(ED$GROUP)
summary(ED)
head(ED)
ED %>%
group_by(GROUP) %>%
get_summary_stats(ANGER, type = "mean_sd")
ggboxplot(ED, x = "GROUP", y = "ANGER")
ED %>%
group_by(GROUP) %>%
get_summary_stats(ANGER, type = "mean_sd")
ggboxplot(ED, x = "GROUP", y = "ANGER")
res.aov <- ED %>% anova_test(ANGER ~ GROUP)
res.aov
pwc <- ED %>% tukey_hsd(ANGER ~ GROUP)
pwc
# Visualization: box plots with p-values
pwc <- pwc %>% add_xy_position(x = "GROUP")
ggboxplot(ED, x = "GROUP", y = "ANGER") +
stat_pvalue_manual(pwc, hide.ns = TRUE) +
labs(
subtitle = get_test_label(res.aov, detailed = TRUE),
caption = get_pwc_label(pwc)
)
waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=F)
#note: some of these aren't used for the code that I run, but for other parts I have hashed out.
library(tidyverse)
library(combinat)
library(gtools)
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(dplyr)
library(gganimate)
library(gifski)
library(png)
library(installr)
library(skimr)
library(rstatix)
library(pwr)
waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=F)
install.packages("waffle")
library(waffle)
waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=F)
waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=FALSE)
x <- c(experiments=100)
waffle::waffle(x, colors=c("lightgrey"))
#waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=FALSE)
x <- c(hypotheses=100)
waffle::waffle(x, colors=c("lightgrey"))
#waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=FALSE)
#x <- c(Hypotheses=100)
#waffle::waffle(x, colors=c("lightgrey"))
waffle::waffle(c(5, 95), colors=c("red", "lightgrey")) + guides(fill=FALSE)
#x <- c(Hypotheses=100)
#waffle::waffle(x, colors=c("lightgrey"))
waffle::waffle(c(False Positive = 5, True Negative = 95), colors=c("red", "lightgrey")) + guides(fill=FALSE)
#x <- c(Hypotheses=100)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(c(False Positive = 5, True Negative = 95), colors=c("red", "lightgrey")) + guides(fill=FALSE)
#x <- c(Hypotheses=100)
#waffle::waffle(x, colors=c("lightgrey"))
waffle::waffle(c(5, 95), colors=c("red", "lightgrey")) + guides(fill=FALSE)
y <- c(False=5, True=95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle::waffle(y, colors=c("red", "lightgrey")) + guides(fill=FALSE)
y <- c(False=5, True=95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(y, colors=c("red", "lightgrey")) + guides(fill=FALSE)
y <- c(False= 5, True = 95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(y, colors=c("red", "lightgrey")) + guides(fill=FALSE)
x <- c(False= 5, True = 95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(x, colors=c("red", "lightgrey")) + guides(fill=FALSE)
x <- c(False = 5, True = 95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(x, colors=c("red", "lightgrey")) + guides(fill=FALSE)
x <- c(False=100)
waffle::waffle(x, colors=c("lightgrey"))
#waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=FALSE)
x <- c(Hypotheses=100)
waffle::waffle(x, colors=c("lightgrey"))
#waffle::waffle(c(40, 60), colors=c("blue", "lightgrey")) + guides(fill=FALSE)
x <- c(False=5, True=95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(x, colors=c("red", "lightgrey")) + guides(fill=FALSE)
x <- c(False=5, True=95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(x, colors=c("red", "lightgrey")) #+ guides(fill=FALSE)
x <- c(False Pos.=5, True Neg.=95)
x <- c(False_Pos.=5, True_Neg.=95)
#waffle::waffle(x, colors=c("lightgrey"))
waffle(x, colors=c("red", "lightgrey")) #+ guides(fill=FALSE)
knitr::include_app("https://danielroelfs.shinyapps.io/FWER_simple/",
height = "400px")
#modified from Spiegelhalter's Figure 9.4 available at:
#https://github.com/dspiegel29/ArtofStatistics/blob/master/09-4-homicide-rates-E%2BW/09-4-homicide-trends-x.Rmd
#note, the hashed-out code is not relevant to my example
#but left in in case someone else wants to use it
df<-EPLGOALS # read data to dataframe df
EPLGOALS<-read_excel("Data/EPLGOALS.xlsx")
#note: some of these aren't used for the code that I run, but for other parts I have hashed out.
library(tidyverse)
library(combinat)
library(gtools)
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(dplyr)
library(gganimate)
library(gifski)
library(png)
library(installr)
library(skimr)
library(rstatix)
library(pwr)
library(waffle)
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
EPLGOALS<-read_excel("Data/EPLGOALS.xlsx")
head(EPLGOALS)
#modified from Spiegelhalter's Figure 9.4 available at:
#https://github.com/dspiegel29/ArtofStatistics/blob/master/09-4-homicide-rates-E%2BW/09-4-homicide-trends-x.Rmd
#note, the hashed-out code is not relevant to my example
#but left in in case someone else wants to use it
df<-EPLGOALS # read data to dataframe df
p <- ggplot(df, aes(x=Season, y=Goals)) # initial plot
p <- p + geom_bar(stat="identity", fill="red") # assign bar chart type
P <- +theme(axis.text.x = element_text(angle = 90)) #rotate lables x axis
#modified from Spiegelhalter's Figure 9.4 available at:
#https://github.com/dspiegel29/ArtofStatistics/blob/master/09-4-homicide-rates-E%2BW/09-4-homicide-trends-x.Rmd
#note, the hashed-out code is not relevant to my example
#but left in in case someone else wants to use it
df<-EPLGOALS # read data to dataframe df
p <- ggplot(df, aes(x=Season, y=Goals)) # initial plot
p <- p + geom_bar(stat="identity", fill="red") # assign bar chart type
P <- p +theme(axis.text.x = element_text(angle = 90)) #rotate lables x axis
#yearLabels <- c("Apr  97-\nMar  98","Apr  00-\nMar  01","Apr  03-\nMar  #04","Apr  06-\nMar  07","Apr 09-\nMar  10","Apr  12-\nMar  13","Apr  #15-\nMar  16") # assign labels for x-axis
p <- p + geom_errorbar(aes(ymin=Lower95CI, ymax=Upper95CI), width=.1) # 95% intervals
#p <- p + scale_x_continuous(breaks=seq(1997, 2015, 3), labels =yearLabels) # attach labels and their break points
p <- p + scale_y_continuous(breaks=seq(0, 1100, 100)) # define break points for y-axis
p <- p + labs(y="Total Goals") # add y-axis label and caption
p
#modified from Spiegelhalter's Figure 9.4 available at:
#https://github.com/dspiegel29/ArtofStatistics/blob/master/09-4-homicide-rates-E%2BW/09-4-homicide-trends-x.Rmd
#note, the hashed-out code is not relevant to my example
#but left in in case someone else wants to use it
df<-EPLGOALS # read data to dataframe df
p <- ggplot(df, aes(x=Season, y=Goals)) # initial plot
p <- p + geom_bar(stat="identity", fill="red") # assign bar chart type
P <- p + theme(axis.text.x = element_text(angle = 90)) #rotate lables x axis
#yearLabels <- c("Apr  97-\nMar  98","Apr  00-\nMar  01","Apr  03-\nMar  #04","Apr  06-\nMar  07","Apr 09-\nMar  10","Apr  12-\nMar  13","Apr  #15-\nMar  16") # assign labels for x-axis
p <- p + geom_errorbar(aes(ymin=Lower95CI, ymax=Upper95CI), width=.1) # 95% intervals
#p <- p + scale_x_continuous(breaks=seq(1997, 2015, 3), labels =yearLabels) # attach labels and their break points
p <- p + scale_y_continuous(breaks=seq(0, 1100, 100)) # define break points for y-axis
p <- p + labs(y="Total Goals") # add y-axis label and caption
p
#modified from Spiegelhalter's Figure 9.4 available at:
#https://github.com/dspiegel29/ArtofStatistics/blob/master/09-4-homicide-rates-E%2BW/09-4-homicide-trends-x.Rmd
#note, the hashed-out code is not relevant to my example
#but left in in case someone else wants to use it
df<-EPLGOALS # read data to dataframe df
p <- ggplot(df, aes(x=Season, y=Goals)) # initial plot
p <- p + geom_bar(stat="identity", fill="red") +theme(axis.text.x = element_text(angle = 90))+scale_x_discrete(name="Season") # assign bar chart type
#P <- p + theme(axis.text.x = element_text(angle = 90)) #rotate lables x axis
#p +geom_bar(stat="identity")+theme(axis.text.x = element_text(angle = #90))+scale_x_discrete(name="Country")+scale_y_continuous(name = "Survival Rate")
#yearLabels <- c("Apr  97-\nMar  98","Apr  00-\nMar  01","Apr  03-\nMar  #04","Apr  06-\nMar  07","Apr 09-\nMar  10","Apr  12-\nMar  13","Apr  #15-\nMar  16") # assign labels for x-axis
p <- p + geom_errorbar(aes(ymin=Lower95CI, ymax=Upper95CI), width=.1) # 95% intervals
#p <- p + scale_x_continuous(breaks=seq(1997, 2015, 3), labels =yearLabels) # attach labels and their break points
p <- p + scale_y_continuous(breaks=seq(0, 1100, 100)) # define break points for y-axis
p <- p + labs(y="Total Goals") # add y-axis label and caption
p
EPLP<-read_excel("Data/EPLGOALSP.xlsx")
summary(EPLP)
head(EPLP)
#visualize the z values simply with control lines
U <- 0.05
#L <- -1.96
p <- ggplot(EPLP, aes(x=Season, y=p2)) + geom_point() +theme(axis.text.x = element_text(angle = 90))+scale_x_discrete(name="Country")
p <- p+ geom_hline(aes(yintercept=U))
#p <- p+ geom_hline(aes(yintercept=L))
p
#visualize the z values simply with control lines
U <- 0.05
#L <- -1.96
p <- ggplot(EPLP, aes(x=Season, y=p2)) + geom_point()
#+theme(axis.text.x = element_text(angle = 90))+scale_x_discrete(name="Country")
p <- p+ geom_hline(aes(yintercept=U))
#p <- p+ geom_hline(aes(yintercept=L))
p
#visualize the z values simply with control lines
U <- 0.05
#L <- -1.96
p <- ggplot(EPLP, aes(x=Season, y=p2)) + geom_point() +theme(axis.text.x = element_text(angle = 90))+scale_x_discrete(name="Country")
p <- p+ geom_hline(aes(yintercept=U))
#p <- p+ geom_hline(aes(yintercept=L))
p
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#note: some of these aren't used for the code that I run, but for other parts I have hashed out.
library(tidyverse)
library(combinat)
library(gtools)
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(dplyr)
library(gganimate)
library(gifski)
library(png)
library(installr)
library(skimr)
library(rstatix)
library(pwr)
library(waffle)
#visualize the z values simply with control lines
U <- 0.0019
#L <- -1.96
p <- ggplot(EPLP, aes(x=Season, y=p2)) + geom_point() +theme(axis.text.x = element_text(angle = 90))+scale_x_discrete(name="Country")
p <- p+ geom_hline(aes(yintercept=U))
#p <- p+ geom_hline(aes(yintercept=L))
p
knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE)
#note: some of these aren't used for the code that I run, but for other parts I have hashed out.
library(tidyverse)
library(combinat)
library(gtools)
library(readxl)
library(ggplot2)
library(ggpubr)
library(mosaic)
library(dplyr)
library(gganimate)
library(gifski)
library(png)
library(installr)
library(TeachingDemos)
CLT<-read_excel("D:/Dropbox/R_Files/Data/CLT.xlsx")
head(CLT)
summary(CLT$Income)
sd(CLT$Income)
ggplot(CLT, aes(x=Income))+geom_histogram(binwidth=400, colour="black", fill="white")
##code modified from: https://www.geeksforgeeks.org/calculate-combinations-and-permutations-in-r/
vec <- CLT$Income
# generating 1 random combination of 2 of the
# Income values
print ("One Random Combination of 2 of the 20 Income Values")
res1<- sample(vec,2,replace=FALSE)
print (res1)
data1<-data.frame(res1)
data1$MDIST <- rowMeans(data1)
head(data1)
data1<-data.frame(res1)
head(data1)
data1<-data.frame(res1)
head(data1)
mean(res1)
vec <- CLT$Income
# generating 1 random combination of 2 of the
# Income values
print ("One Random Combination of 2 of the 20 Income Values")
res1<- sample(vec,2,replace=FALSE)
print (res1)
data1<-data.frame(res1)
head(data1)
mean(res1)
